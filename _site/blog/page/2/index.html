


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    
  <title>GIS programmer writing Python in Emacs</title>
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
<link rel="alternate" type="application/atom+xml" title="Atom 1.0"
href="/blog/feed/atom" />
<link rel='stylesheet' href='/css/pygments_murphy.css' type='text/css' />

<link rel='stylesheet' href='/css/site.css' type='text/css' />


  </head>
  <body>
    <div id="content">
      
  <h1><a href="/">GIS programmer writing Python in Emacs</a></h1>
<hr/>


      <div id="main_block">
        <div id="prose_block">
          
  
<div class="blog_post">
  <a name="post-3---unicode-test---how-about-some-日本語テスト"></a>
  <h2 class="blog_post_title"><a href="/2009/08/22/post-3---unicode-test---how-about-some-日本語テスト" rel="bookmark" title="Permanent Link to Post 3 - Unicode Test - How about some 日本語テスト">Post 3 - Unicode Test - How about some 日本語テスト</a></h2>
  <small>August 22, 2009 at 03:22 PM | categories: 

<a href='/blog/category/unicode'>Unicode</a>
</small><p/>
  <div class="post_prose">
    
  <p>Anglo-Saxon Rune Poem:</p>
<p>ᚠᛇᚻ᛫ᛒᛦᚦ᛫ᚠᚱᚩᚠᚢᚱ᛫ᚠᛁᚱᚪ᛫ᚷᛖᚻᚹᛦᛚᚳᚢᛗ
ᛋᚳᛖᚪᛚ᛫ᚦᛖᚪᚻ᛫ᛗᚪᚾᚾᚪ᛫ᚷᛖᚻᚹᛦᛚᚳ᛫ᛗᛁᚳᛚᚢᚾ᛫ᚻᛦᛏ᛫ᛞᚫᛚᚪᚾ
ᚷᛁᚠ᛫ᚻᛖ᛫ᚹᛁᛚᛖ᛫ᚠᚩᚱ᛫ᛞᚱᛁᚻᛏᚾᛖ᛫ᛞᚩᛗᛖᛋ᛫ᚻᛚᛇᛏᚪᚾ᛬</p>
<p>Tamil poetry:</p>
<p>யாமறிந்த மொழிகளிலே தமிழ்மொழி போல் இனிதாவது எங்கும் காணோம்,
பாமரராய் விலங்குகளாய், உலகனைத்தும் இகழ்ச்சிசொலப் பான்மை கெட்டு,
நாமமது தமிழரெனக் கொண்டு இங்கு வாழ்ந்திடுதல் நன்றோ? சொல்லீர்!
தேமதுரத் தமிழோசை உலகமெலாம் பரவும்வகை செய்தல் வேண்டும்.</p>
<p>I can eat glass:
私はガラスを食べられます。それは私を傷つけません。
Կրնամ ապակի ուտել և ինծի անհանգիստ չըներ։
I kå Glas frässa, ond des macht mr nix!
᚛᚛ᚉᚑᚅᚔᚉᚉᚔᚋ ᚔᚈᚔ ᚍᚂᚐᚅᚑ ᚅᚔᚋᚌᚓᚅᚐ᚜
אני יכול לאכול זכוכית וזה לא מזיק לי
काचं शक्नोम्यत्तुम् । नोपहिनस्ति माम् ॥ </p>

  </div>
</div>



  <hr class="interblog" />
  
<div class="blog_post">
  <a name="post-2"></a>
  <h2 class="blog_post_title"><a href="/2009/07/24/post-2" rel="bookmark" title="Permanent Link to Post 2">Post 2</a></h2>
  <small>July 24, 2009 at 04:20 PM | categories: 

<a href='/blog/category/category-2'>Category 2</a>, <a href='/blog/category/category-1'>Category 1</a>
</small><p/>
  <div class="post_prose">
    
  <p>This is post #2</p>

  </div>
</div>



  <hr class="interblog" />
  
<div class="blog_post">
  <a name="post-1"></a>
  <h2 class="blog_post_title"><a href="/2009/07/23/post-1" rel="bookmark" title="Permanent Link to Post 1">Post 1</a></h2>
  <small>July 23, 2009 at 03:22 PM | categories: 

<a href='/blog/category/category-1'>Category 1</a>
</small><p/>
  <div class="post_prose">
    
  <p>This is post #1
The gibberish (nonsense text) presented here is generated by a very simple computer program. Given some sample text, say Shakespeare, as input, the computer generates output which is random, but which has the same statistical distribution of characters or combinations of characters. (A character may be a letter, a digit, a space, a punctuation mark, etc.)</p>
<p>In level 1 gibberish, the output has the same distribution of single characters as the input. For example, the probability of seeing a character like "e" or "z" or "." will be approximately the same in the output as in the input. In level 2 gibberish, the output has the same distribution of character pairs as the input. For example, the probability of seeing a pair like "th" or "te" or "t." will be approximately the same in the output as in the input. In general, in level n gibberish, the output has the same distribution of groups of n characters (n-tuples) as the input. (The algorithm is a letter-based Markov text generator. Level n gibberish is a Markov chain of order n-1.)</p>
<p>It is amazing how well this simple algorithm works, even for very low level numbers. For example, at level 2, you can easily recognize different languages. At level 3 you can recognize the styles of different authors.</p>
<p>For even more fun, the gibberish generator can easily blend two different languages or two different authors. If the input is simply the text from author A followed by the text from author B, the output will be a smooth blend of the two.</p>
<p>To generate your own gibberish, go to Gibberish Generator.</p>
<p>To see some samples, go to Gibberish Samples.</p>
<p>A final thought: Is the human brain simply a level 100 gibberish generator?</p>
<p>References: Program named Mark V. Shaney (pun on Markov Chain) by Bruce Ellis, Rob Pike, and Don P. Mitchell, publicized in the June, 1989, Scientific American "Computer Recreations" column titled "A potpourri of programmed prose and prosody" by A. K. Dewdney.</p>

  </div>
</div>



  <hr class="interblog" />
 <a href="../1">« Previous Page</a>

        </div><!-- End Prose Block -->
      </div><!-- End Main Block -->
      <div id="footer">
        
  <hr/>
  <p id="credits">
Powered by <a href="http://www.blogofile.com">Blogofile</a>.<br/>
<br/>
RSS feeds for <a href="/blog/feed">Entries</a>
<br>
</p>


      </div> <!-- End Footer -->
    </div> <!-- End Content -->
  </body>
</html>




