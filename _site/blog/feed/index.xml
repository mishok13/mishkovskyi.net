<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <title>GIS programmer writing Python in Emacs</title>
    <link>http://mishkovskyi.net/blog</link>
    <description>(loop [code '()] (if (perfect? code) code (recur (conj code bug))))</description>
    <pubDate>Wed, 13 Jul 2011 13:39:55 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <item>
      <title>Syntax highlight test</title>
      <link>http://mishkovskyi.netblog/2009/08/29/syntax-highlight-test</link>
      <pubDate>Sat, 29 Aug 2009 15:25:00 EEST</pubDate>
      <category><![CDATA[General Stuff]]></category>
      <guid isPermaLink="true">http://mishkovskyi.netblog/2009/08/29/syntax-highlight-test</guid>
      <description>Syntax highlight test</description>
      <content:encoded><![CDATA[<p>This post contains some highlighted python code:</p>
<div class="pygments_murphy"><pre><span class="kn">import</span> <span class="nn">this</span>

<p><span class="k">if</span> <span class="n"><strong>name</strong></span> <span class="o">==</span> <span class="s">&quot;main&quot;</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">&quot;Hello, World!&quot;</span>
</pre></div></p>]]></content:encoded>
    </item>
    <item>
      <title>Post 7</title>
      <link>http://mishkovskyi.netblog/2009/08/29/post-7</link>
      <pubDate>Sat, 29 Aug 2009 15:25:00 EEST</pubDate>
      <category><![CDATA[General Stuff]]></category>
      <guid isPermaLink="true">http://mishkovskyi.netblog/2009/08/29/post-7</guid>
      <description>Post 7</description>
      <content:encoded><![CDATA[<p>This is post #7
The gibberish (nonsense text) presented here is generated by a very simple computer program. Given some sample text, say Shakespeare, as input, the computer generates output which is random, but which has the same statistical distribution of characters or combinations of characters. (A character may be a letter, a digit, a space, a punctuation mark, etc.)</p>
<p>In level 1 gibberish, the output has the same distribution of single characters as the input. For example, the probability of seeing a character like "e" or "z" or "." will be approximately the same in the output as in the input. In level 2 gibberish, the output has the same distribution of character pairs as the input. For example, the probability of seeing a pair like "th" or "te" or "t." will be approximately the same in the output as in the input. In general, in level n gibberish, the output has the same distribution of groups of n characters (n-tuples) as the input. (The algorithm is a letter-based Markov text generator. Level n gibberish is a Markov chain of order n-1.)</p>
<p>It is amazing how well this simple algorithm works, even for very low level numbers. For example, at level 2, you can easily recognize different languages. At level 3 you can recognize the styles of different authors.</p>
<p>For even more fun, the gibberish generator can easily blend two different languages or two different authors. If the input is simply the text from author A followed by the text from author B, the output will be a smooth blend of the two.</p>
<p>To generate your own gibberish, go to Gibberish Generator.</p>
<p>To see some samples, go to Gibberish Samples.</p>
<p>A final thought: Is the human brain simply a level 100 gibberish generator?</p>
<p>References: Program named Mark V. Shaney (pun on Markov Chain) by Bruce Ellis, Rob Pike, and Don P. Mitchell, publicized in the June, 1989, Scientific American "Computer Recreations" column titled "A potpourri of programmed prose and prosody" by A. K. Dewdney.</p>]]></content:encoded>
    </item>
    <item>
      <title>Post 6</title>
      <link>http://mishkovskyi.netblog/2009/08/29/post-6</link>
      <pubDate>Sat, 29 Aug 2009 15:24:00 EEST</pubDate>
      <category><![CDATA[General Stuff]]></category>
      <guid isPermaLink="true">http://mishkovskyi.netblog/2009/08/29/post-6</guid>
      <description>Post 6</description>
      <content:encoded><![CDATA[<p>This is post #6</p>]]></content:encoded>
    </item>
    <item>
      <title>Post 5</title>
      <link>http://mishkovskyi.netblog/2009/08/29/post-5</link>
      <pubDate>Sat, 29 Aug 2009 15:23:00 EEST</pubDate>
      <category><![CDATA[General Stuff]]></category>
      <guid isPermaLink="true">http://mishkovskyi.netblog/2009/08/29/post-5</guid>
      <description>Post 5</description>
      <content:encoded><![CDATA[<p>This is post #5</p>]]></content:encoded>
    </item>
    <item>
      <title>Post 4</title>
      <link>http://mishkovskyi.netblog/2009/08/29/post-4</link>
      <pubDate>Sat, 29 Aug 2009 15:22:00 EEST</pubDate>
      <category><![CDATA[General Stuff]]></category>
      <guid isPermaLink="true">http://mishkovskyi.netblog/2009/08/29/post-4</guid>
      <description>Post 4</description>
      <content:encoded><![CDATA[<p>This is post #4</p>]]></content:encoded>
    </item>
    <item>
      <title>Post 3 - Unicode Test - How about some 日本語テスト</title>
      <link>http://mishkovskyi.netblog/2009/08/22/post-3---unicode-test---how-about-some-日本語テスト</link>
      <pubDate>Sat, 22 Aug 2009 15:22:00 EEST</pubDate>
      <category><![CDATA[Unicode]]></category>
      <guid isPermaLink="true">http://mishkovskyi.netblog/2009/08/22/post-3---unicode-test---how-about-some-日本語テスト</guid>
      <description>Post 3 - Unicode Test - How about some 日本語テスト</description>
      <content:encoded><![CDATA[<p>Anglo-Saxon Rune Poem:</p>
<p>ᚠᛇᚻ᛫ᛒᛦᚦ᛫ᚠᚱᚩᚠᚢᚱ᛫ᚠᛁᚱᚪ᛫ᚷᛖᚻᚹᛦᛚᚳᚢᛗ
ᛋᚳᛖᚪᛚ᛫ᚦᛖᚪᚻ᛫ᛗᚪᚾᚾᚪ᛫ᚷᛖᚻᚹᛦᛚᚳ᛫ᛗᛁᚳᛚᚢᚾ᛫ᚻᛦᛏ᛫ᛞᚫᛚᚪᚾ
ᚷᛁᚠ᛫ᚻᛖ᛫ᚹᛁᛚᛖ᛫ᚠᚩᚱ᛫ᛞᚱᛁᚻᛏᚾᛖ᛫ᛞᚩᛗᛖᛋ᛫ᚻᛚᛇᛏᚪᚾ᛬</p>
<p>Tamil poetry:</p>
<p>யாமறிந்த மொழிகளிலே தமிழ்மொழி போல் இனிதாவது எங்கும் காணோம்,
பாமரராய் விலங்குகளாய், உலகனைத்தும் இகழ்ச்சிசொலப் பான்மை கெட்டு,
நாமமது தமிழரெனக் கொண்டு இங்கு வாழ்ந்திடுதல் நன்றோ? சொல்லீர்!
தேமதுரத் தமிழோசை உலகமெலாம் பரவும்வகை செய்தல் வேண்டும்.</p>
<p>I can eat glass:
私はガラスを食べられます。それは私を傷つけません。
Կրնամ ապակի ուտել և ինծի անհանգիստ չըներ։
I kå Glas frässa, ond des macht mr nix!
᚛᚛ᚉᚑᚅᚔᚉᚉᚔᚋ ᚔᚈᚔ ᚍᚂᚐᚅᚑ ᚅᚔᚋᚌᚓᚅᚐ᚜
אני יכול לאכול זכוכית וזה לא מזיק לי
काचं शक्नोम्यत्तुम् । नोपहिनस्ति माम् ॥ </p>]]></content:encoded>
    </item>
    <item>
      <title>Post 2</title>
      <link>http://mishkovskyi.netblog/2009/07/24/post-2</link>
      <pubDate>Fri, 24 Jul 2009 16:20:00 EEST</pubDate>
      <category><![CDATA[Category 2]]></category>
      <category><![CDATA[Category 1]]></category>
      <guid isPermaLink="true">http://mishkovskyi.netblog/2009/07/24/post-2</guid>
      <description>Post 2</description>
      <content:encoded><![CDATA[<p>This is post #2</p>]]></content:encoded>
    </item>
    <item>
      <title>Post 1</title>
      <link>http://mishkovskyi.netblog/2009/07/23/post-1</link>
      <pubDate>Thu, 23 Jul 2009 15:22:00 EEST</pubDate>
      <category><![CDATA[Category 1]]></category>
      <guid isPermaLink="true">http://mishkovskyi.netblog/2009/07/23/post-1</guid>
      <description>Post 1</description>
      <content:encoded><![CDATA[<p>This is post #1
The gibberish (nonsense text) presented here is generated by a very simple computer program. Given some sample text, say Shakespeare, as input, the computer generates output which is random, but which has the same statistical distribution of characters or combinations of characters. (A character may be a letter, a digit, a space, a punctuation mark, etc.)</p>
<p>In level 1 gibberish, the output has the same distribution of single characters as the input. For example, the probability of seeing a character like "e" or "z" or "." will be approximately the same in the output as in the input. In level 2 gibberish, the output has the same distribution of character pairs as the input. For example, the probability of seeing a pair like "th" or "te" or "t." will be approximately the same in the output as in the input. In general, in level n gibberish, the output has the same distribution of groups of n characters (n-tuples) as the input. (The algorithm is a letter-based Markov text generator. Level n gibberish is a Markov chain of order n-1.)</p>
<p>It is amazing how well this simple algorithm works, even for very low level numbers. For example, at level 2, you can easily recognize different languages. At level 3 you can recognize the styles of different authors.</p>
<p>For even more fun, the gibberish generator can easily blend two different languages or two different authors. If the input is simply the text from author A followed by the text from author B, the output will be a smooth blend of the two.</p>
<p>To generate your own gibberish, go to Gibberish Generator.</p>
<p>To see some samples, go to Gibberish Samples.</p>
<p>A final thought: Is the human brain simply a level 100 gibberish generator?</p>
<p>References: Program named Mark V. Shaney (pun on Markov Chain) by Bruce Ellis, Rob Pike, and Don P. Mitchell, publicized in the June, 1989, Scientific American "Computer Recreations" column titled "A potpourri of programmed prose and prosody" by A. K. Dewdney.</p>]]></content:encoded>
    </item>
  </channel>
</rss>
